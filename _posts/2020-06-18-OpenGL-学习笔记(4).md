---
title: OpenGL 学习笔记(4)
categories: OpenGL
tags: OpenGL
---

# 坐标系统

关键词：

- 标准化设备坐标(Normalized Device Coordinate, NDC)：每个顶点的**x**，**y**，**z**坐标都应该在**-1.0**到**1.0**之间，超出这个坐标范围的顶点都将不可见。
- 局部空间(Local Space，或者称为物体空间(Object Space))
- 世界空间(World Space)
- 观察空间(View Space，或者称为视觉空间(Eye Space))
- 裁剪空间(Clip Space)
- 屏幕空间(Screen Space)

## 概述

关键词：

- 模型(Model)矩阵
- 观察(View)矩阵
- 投影(Projection)矩阵
- 局部空间坐标
- 世界空间坐标
- 观察空间坐标
- 裁剪空间坐标
- 屏幕空间坐标

<img src="https://learnopengl-cn.github.io/img/01/08/coordinate_systems.png" alt="coordinate_systems" />

> 将顶点变换到各个不同的空间的原因是有些操作在特定的坐标系统中才有意义且更方便。例如，当需要对物体进行修改的时候，在局部空间中来操作会更说得通；如果要对一个物体做出一个相对于其它物体位置的操作时，在世界坐标系中来做这个才更说得通，等等。

模型矩阵：模型矩阵是一种变换矩阵，它能通过对物体进行位移、缩放、旋转来将它置于它本应该在的位置或朝向。从而将物体的坐标从局部空间变换到世界空间。

观察矩阵：它被用来将世界坐标变换到观察空间。

> 观察空间是将世界空间坐标转化为用户视野前方的坐标而产生的结果。因此观察空间就是从摄像机的视角所观察到的空间。而这通常是由一系列的位移和旋转的组合来完成，平移/旋转场景从而使得特定的对象被变换到摄像机的前方。



## 裁剪空间

关键词：

- 投影矩阵：正射投影矩阵和透视投影矩阵

- 观察箱：平截头体

- 投影

  > 将特定范围内的坐标转化到标准化设备坐标系的过程（而且它很容易被映射到2D观察空间坐标）被称之为投影(Projection)

- 透视除法：

  > 透视除法是将4D裁剪空间坐标变换为3D标准化设备坐标的过程。这一步会在每一个顶点着色器运行的最后被自动执行。在这个过程中我们将位置向量的x，y，z分量分别除以向量的齐次w分量。

### 正射投影

> 创建一个正射投影矩阵需要指定可见平截头体的宽、高和长度。

```c++
glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f);
```



![orthographic projection frustum](https://learnopengl-cn.github.io/img/01/08/orthographic_frustum.png)

### 透视投影

> 这个投影矩阵将给定的平截头体范围映射到裁剪空间，除此之外还修改了每个顶点坐标的w值，从而使得离观察者越远的顶点坐标w分量越大。
>
> 顶点坐标的每个分量都会除以它的w分量，距离观察者越远顶点坐标就会越小。

```c++
glm::mat4 proj = glm::perspective(glm::radians(45.0f), (float)width/(float)height, 0.1f, 100.0f);
```

![ perspective_frustum](https://learnopengl-cn.github.io/img/01/08/perspective_frustum.png)

拓展阅读：

- [OpenGL Projection Matrix](http://www.songho.ca/opengl/gl_projectionmatrix.html)

# 进入3D

将原物体的顶点坐标经过一些列的变换之后的坐标

模型矩阵：将顶点的坐标经过位移、缩放和旋转变换之后的坐标，可以视为世界空间坐标。（相当于物体从世界坐标原点开始进行变换）

观察矩阵：如何在场景中移动，见下节教程（观察矩阵是如何确定的？）

投影矩阵：定义平截头体

```c++
#version 330 core
layout (location = 0) in vec3 aPos;
...
uniform mat4 model;
uniform mat4 view;
uniform mat4 projection;

void main()
{
    // 注意乘法要从右向左读
    gl_Position = projection * view * model * vec4(aPos, 1.0);
    ...
}
```

# 更多的3D

> 立方体的某些本应被遮挡住的面被绘制在了这个立方体其他面之上。之所以这样是因为OpenGL是一个三角形一个三角形地来绘制你的立方体的，所以即便之前那里有东西它也会覆盖之前的像素。因为这个原因，有些三角形会被绘制在其它三角形上面，虽然它们本不应该是被覆盖的。

关键词：

- Z 缓冲(Z-buffer)：存储深度信息

- 深度测试(Depth Testing)：

  > 深度值存储在每个片段里面（作为片段的**z**值），当片段想要输出它的颜色时，OpenGL会将它的深度值和z缓冲进行比较，如果当前的片段在其它片段之后，它将会被丢弃，否则将会覆盖。

```c++
glEnable(GL_DEPTH_TEST); //启用深度测试
glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT); //清除上一帧的深度缓冲
```

# 摄像机

> OpenGL本身没有**摄像机**(Camera)的概念，但我们可以通过把场景中的所有物体往相反方向移动的方式来模拟出摄像机，产生一种**我们**在移动的感觉，而不是场景在移动。

## 摄像机/观察空间

> 观察矩阵把所有的世界坐标变换为相对于摄像机位置与方向的观察坐标。

关键词：

- 摄像机位置	
- 摄像机方向
- 右轴
- 上轴

**创建一个三个单位轴相互垂直的、以摄像机的位置为原点的坐标系。**

![img](https://learnopengl-cn.github.io/img/01/09/camera_axes.png)

**摄像机位置**：世界空间中一个指向摄像机位置的向量。

```c++
glm::vec3 cameraPos = glm::vec3(0.0f, 0.0f, 3.0f);
```



**摄像机方向**：摄像机位置向量 - 摄像机指向目标向量 

```c++
glm::vec3 cameraTarget = glm::vec3(0.0f, 0.0f, 0.0f);
glm::vec3 cameraDirection = glm::normalize(cameraPos - cameraTarget);
```



**右轴**：

- 右向量：由上向量和方向向量叉乘得到
- 上向量：自定义

```c++
glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f); 
glm::vec3 cameraRight = glm::normalize(glm::cross(up, cameraDirection));
```



**上轴**：

- 上轴：右向量和方向向量叉乘得到

```c++
glm::vec3 cameraUp = glm::cross(cameraDirection, cameraRight);
```

## Look At

LookAt 矩阵：它会创建一个看着(Look at)给定目标的观察矩阵。

> LookAt矩阵作为观察矩阵可以很高效地把所有世界坐标变换到刚刚定义的观察空间。

$$LookAt = \begin{bmatrix} \color{red}{R_x} & \color{red}{R_y} & \color{red}{R_z} & 0 \\ \color{green}{U_x} & \color{green}{U_y} & \color{green}{U_z} & 0 \\ \color{blue}{D_x} & \color{blue}{D_y} & \color{blue}{D_z} & 0 \\ 0 & 0 & 0  & 1 \end{bmatrix} * \begin{bmatrix} 1 & 0 & 0 & -\color{purple}{P_x} \\ 0 & 1 & 0 & -\color{purple}{P_y} \\ 0 & 0 & 1 & -\color{purple}{P_z} \\ 0 & 0 & 0  & 1 \end{bmatrix}$$

其中$$\color{red}R$$是右向量，$$\color{red}U$$是上向量，$$\color{red}D$$是方向向量，$$\color{red}P$$是摄像机位置向量。

GLM支持：给定一个摄像机位置，一个目标位置和一个表示世界空间中的上向量的向量，通过glm::LookAt函数就能创建一个观察矩阵。

```c++
glm::mat4 view;
view = glm::lookAt(glm::vec3(0.0f, 0.0f, 3.0f), 
           glm::vec3(0.0f, 0.0f, 0.0f), 
           glm::vec3(0.0f, 1.0f, 0.0f));
```

# 自由移动

为了能够自由移动，需要改变摄像机的位置。

定义一些摄像机变量：

```c++
glm::vec3 cameraPos   = glm::vec3(0.0f, 0.0f,  3.0f);
glm::vec3 cameraFront = glm::vec3(0.0f, 0.0f, -1.0f);
glm::vec3 cameraUp    = glm::vec3(0.0f, 1.0f,  0.0f);
```

LookAt函数：

```c++
view = glm::lookAt(cameraPos, cameraPos + cameraFront, cameraUp);
```

目标位置 = 摄像机位置 + 方向向量，这样可以保证无论怎么移动，摄像机方向不变。

实现左右前后移动：

```c++
cameraPos += cameraSpeed * cameraFront;
cameraPos -= glm::normalize(glm::cross(cameraFront, cameraUp)) * cameraSpeed;
```

## 移动速度

> 目前我们的移动速度是个常量。理论上没什么问题，但是实际情况下根据处理器的能力不同，有些人可能会比其他人每秒绘制更多帧，也就是以更高的频率调用processInput函数。图形程序和游戏通常会跟踪一个时间差(Deltatime)变量，它储存了渲染上一帧所用的时间。

# 视角移动

> 为了能够改变视角，我们需要根据鼠标的输入改变cameraFront向量。

## 欧拉角

关键词：俯仰角(Pitch)、偏航角(Yaw)和滚转角(Roll)

![img](https://learnopengl-cn.github.io/img/01/09/camera_pitch_yaw_roll.png)

> 每个欧拉角都有一个值来表示，把三个角结合起来我们就能够计算3D空间中任何的旋转向量了。

鼠标移动调整欧拉角：

```c++
float xoffset = xpos - lastX;
float yoffset = lastY - ypos; 
lastX = xpos;
lastY = ypos;

float sensitivity = 0.05;
xoffset *= sensitivity;
yoffset *= sensitivity;

yaw   += xoffset;
pitch += yoffset;
```

计算方向向量：

```c++
glm::vec3 front;
front.x = cos(glm::radians(pitch)) * cos(glm::radians(yaw));
front.y = sin(glm::radians(pitch));
front.z = cos(glm::radians(pitch)) * sin(glm::radians(yaw));
cameraFront = glm::normalize(front);
```

## 缩放

缩放通过调整视野实现，使用fov变量作为摄像机的视野大小。

```c++
projection = glm::perspective(glm::radians(fov), 800.0f / 600.0f, 0.1f, 100.0f);
```

